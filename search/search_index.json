{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"en/","title":"FastGRPC","text":"<p>Build gRPC services with a friendly, FastAPI-like developer experience.</p> <p>FastGRPC lets you write standard Python async callables annotated with Pydantic models and turns them into a full gRPC service at runtime. It supports unary and all streaming patterns, dependency injection, middlewares, server reflection, routers, and optional OpenTelemetry tracing.</p> <p>What you get:</p> <ul> <li>Simple decorator-based RPC registration</li> <li>Unary and streaming handlers (client, server, bidirectional)</li> <li>Pydantic models as request/response schemas</li> <li>Dependency injection via <code>fast_depends</code></li> <li>Middlewares (logging included; tracing optional)</li> <li>gRPC server reflection enabled by default</li> <li>A lightweight dynamic client powered by reflection</li> </ul> <p>Continue with the Tutorial to get a service running in minutes.</p> <p>Quick links:</p> <ul> <li>Tutorial \u2014 Installation, First Steps, Handlers &amp; Schemas, Streaming</li> <li>User Guide \u2014 Dependencies, Routers, Middlewares, Context, Errors, Reflection</li> <li>Observability \u2014 OpenTelemetry tracing</li> <li>Client \u2014 Call your services from Python dynamically</li> <li>Deployment \u2014 Run in production</li> <li>Examples \u2014 Copy-paste ready snippets</li> </ul>"},{"location":"en/client/python-client/","title":"Python Client","text":"<p>FastGRPC includes a lightweight dynamic client that uses reflection\u2014no generated stubs needed.</p> <p>Basic unary call:</p> <pre><code>from fastgrpcio.calls import GRPCClient\n\nasync with GRPCClient(\"localhost:50051\") as client:\n    resp = await client.unary_unary(\n        service_name=\"hello_app.HelloApp\",\n        method_name=\"say_hello\",\n        body={\"name\": \"World\"},\n        metadata={\"authorization\": \"secret\"},  # optional\n    )\n</code></pre> <p>Notes:</p> <ul> <li><code>service_name</code> is <code>&lt;package&gt;.&lt;ServiceName&gt;</code> as compiled (see your <code>app_package_name</code> and <code>app_name</code>).</li> <li><code>method_name</code> is the name you used in <code>@app.register_as(\"...\")</code>.</li> <li>For streaming, use <code>unary_stream</code>, <code>stream_unary</code>, and <code>stream_stream</code> helpers.</li> </ul>"},{"location":"en/deployment/deployment/","title":"Deployment","text":"<p>FastGRPC runs on <code>grpc.aio.server</code> and is production-ready behind standard process managers and load balancers.</p> <p>Checklist:</p> <ul> <li>Choose a stable port and bind to <code>0.0.0.0</code> inside containers.</li> <li>Use multiple workers via the thread pool size (<code>worker_count</code>) if needed.</li> <li>Put a reverse proxy or L4 load balancer in front when scaling horizontally.</li> <li>Enable tracing and metrics with OpenTelemetry if observability matters.</li> </ul> <p>Example Dockerfile snippet:</p> <pre><code>FROM python:3.11-slim\nWORKDIR /app\nCOPY . .\nRUN pip install --no-cache-dir fastgrpcio\nCMD [\"python\", \"-m\", \"your_package.server\"]\n</code></pre> <p>Health checks</p> <ul> <li>Consider adding a lightweight unary RPC for readiness/liveness.</li> <li>Alternatively, expose a simple HTTP sidecar if your environment requires HTTP health checks.</li> </ul>"},{"location":"en/examples/examples/","title":"Examples","text":"<p>Two end-to-end examples are provided in the repository under <code>examples/</code>.</p> <p>Example 1 \u2014 end-to-end with tracing and a router (<code>examples/example.py</code>):</p> <p>Highlights:</p> <ul> <li>Registers unary and streaming RPCs</li> <li>Configures OpenTelemetry tracer and OTLP exporter</li> <li>Uses the dynamic Python client from inside a handler</li> <li>Adds a separate router that compiles as another service</li> </ul> <p>Example 2 \u2014 a second service (<code>examples/example2.py</code>):</p> <ul> <li>Runs on a different port</li> <li>Provides RPCs that can be called from the first service</li> </ul> <p>Tip: run both to test inter-service calls and trace propagation. When calling from a handler, pass <code>context.meta</code> to forward incoming metadata and trace context to downstream services.</p>"},{"location":"en/guide/context/","title":"Context","text":"<p>Handlers receive a <code>GRPCContext</code> providing access to:</p> <ul> <li><code>meta</code>: merged incoming metadata and trace context</li> <li><code>abort(code, details, trailing_metadata)</code>: abort the call with a gRPC status</li> </ul> <p>Example:</p> <pre><code>from fastgrpcio.context import GRPCContext\nimport grpc\n\n@app.register_as(\"needs_auth\")\nasync def needs_auth(data: Request, context: GRPCContext) -&gt; Response:\n    if context.meta.get(\"authorization\") != \"secret\":\n        await context.abort(grpc.StatusCode.UNAUTHENTICATED, \"Missing or invalid token\")\n    return Response(message=\"ok\")\n</code></pre>"},{"location":"en/guide/dependencies/","title":"Dependencies","text":"<p>FastGRPC integrates with <code>fast_depends</code> to provide a simple dependency injection mechanism.</p> <p>Use standard callables and declare them in your handler signature via keyword arguments. The library injects them at runtime.</p> <pre><code>import fast_depends\n\ndef config() -&gt; dict:\n    return {\"greeting\": \"Hello\"}\n\n@app.register_as(\"unary_unary\")\nasync def handler(data: Request, context: GRPCContext, cfg: dict = fast_depends.Depends(config)) -&gt; Response:\n    return Response(message=f\"{cfg['greeting']}, {data.name}\")\n</code></pre> <p>Notes:</p> <ul> <li>Dependencies can be sync or async.</li> <li>Values are resolved per-call.</li> <li>If validation fails on the request body, the framework returns a gRPC error with details.</li> </ul>"},{"location":"en/guide/error-handling/","title":"Error Handling","text":"<p>Validation errors</p> <ul> <li>Request messages are converted to Pydantic models. If validation fails, FastGRPC converts the error to a gRPC status and aborts the call with structured details.</li> </ul> <p>Manual errors</p> <ul> <li>Use <code>context.abort(StatusCode, details)</code> to end a call with a specific status.</li> </ul> <p>Examples:</p> <pre><code>from pydantic import BaseModel, Field\nimport grpc\n\nclass Request(BaseGRPCSchema):\n    limit: int = Field(ge=1, le=100)\n\n@app.register_as(\"bounded\")\nasync def bounded(data: Request, context: GRPCContext) -&gt; Response:\n    return Response(message=f\"limit={data.limit}\")\n\n@app.register_as(\"forbidden\")\nasync def forbidden(_: Request, context: GRPCContext) -&gt; Response:\n    await context.abort(grpc.StatusCode.PERMISSION_DENIED, \"Not allowed\")\n</code></pre>"},{"location":"en/guide/middlewares/","title":"Middlewares","text":"<p>Middlewares let you run logic before/after handlers. FastGRPC ships with a <code>LoggingMiddleware</code> by default and supports custom middlewares by subclassing <code>BaseMiddleware</code>.</p> <p>Key hooks:</p> <ul> <li><code>handle_unary(...)</code> for unary RPCs</li> <li><code>handle_stream(...)</code> for server/bidi streaming</li> <li><code>handle_client_stream(...)</code> for client streaming</li> </ul> <p>Add a middleware:</p> <pre><code>from fastgrpcio.middlewares import BaseMiddleware\n\nclass MyMiddleware(BaseMiddleware):\n    async def handle_unary(self, request, context, call_next, user_func, request_model, response_class, handler, unary_type, **kw):\n        # pre\n        resp = await call_next(request, context)\n        # post\n        return resp\n\napp.add_middleware(MyMiddleware())\n</code></pre> <p>Middlewares run in registration order and wrap the execution chain.</p>"},{"location":"en/guide/reflection/","title":"Reflection","text":"<p>Server reflection is enabled by default. This makes your service discoverable by tooling and clients without distributing <code>.proto</code> files.</p> <p>What you can do:</p> <ul> <li>Explore services and methods with <code>grpcurl</code> or Evans</li> <li>Generate clients dynamically</li> <li>Use FastGRPC\u2019s Python client that leverages reflection</li> </ul> <p>No extra setup is needed\u2014reflection is registered when the server starts.</p>"},{"location":"en/guide/routers/","title":"Routers","text":"<p>Group related RPCs with <code>FastGRPCRouter</code> and include them into the main app. Each router compiles into its own gRPC service with its own <code>app_name</code> and <code>app_package_name</code>.</p> <pre><code>from fastgrpcio.fast_grpc import FastGRPCRouter\n\nrouter = FastGRPCRouter(app_name=\"RouterApp\", app_package_name=\"router_app\")\n\n@router.register_as(\"unary_unary2\")\nasync def logic(data: Request, context: GRPCContext) -&gt; Response:\n    return Response(message=f\"Router logic for {data.name}\")\n\napp.include_router(router)\n</code></pre> <p>Result: your server exposes multiple compiled services (one for the main app, one per router). Reflection lists them all.</p>"},{"location":"en/observability/tracing/","title":"Tracing","text":"<p>FastGRPC can propagate and export traces with OpenTelemetry using the <code>TracingMiddleware</code>.</p> <p>Example with OTLP exporter (compatible with collectors like the OpenTelemetry Collector or Jaeger via OTLP):</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n\nfrom fastgrpcio.tracing.middleware import TracingMiddleware\n\nresource = Resource.create({\"service.name\": \"HelloApp\"})\nprovider = TracerProvider(resource=resource)\ntrace.set_tracer_provider(provider)\n\nexporter = OTLPSpanExporter(endpoint=\"http://localhost:4317\", insecure=True)\nprovider.add_span_processor(BatchSpanProcessor(exporter))\n\napp.add_middleware(TracingMiddleware(tracer_provider=provider))\n</code></pre> <p>When calling other FastGRPC services from a handler (e.g., via the Python client), pass <code>context.meta</code> as metadata to propagate trace context.</p>"},{"location":"en/project/contributing/","title":"Contributing","text":"<p>Thanks for your interest in contributing! A few pointers to get started:</p> <ul> <li>Set up a Python 3.11+ environment.</li> <li>Install dev dependencies as needed for linting and tests.</li> <li>Run and edit the examples under <code>examples/</code> to validate behavior.</li> <li>Keep changes focused and add or update docs in <code>docs/en/</code> where useful.</li> </ul> <p>Docs</p> <ul> <li>The docs use MkDocs Material with i18n. English is the default locale.</li> <li>Build locally with:</li> </ul> <pre><code>pip install mkdocs mkdocs-material mkdocs-static-i18n\nmkdocs serve\n</code></pre> <p>Code style</p> <ul> <li>Follow existing naming and structure in <code>fastgrpcio/</code>.</li> <li>Prefer small, composable functions and clear type hints.</li> </ul> <p>Thank you for making FastGRPC better!</p>"},{"location":"en/project/release-notes/","title":"Release Notes","text":"<p>The project follows semantic versioning when possible. Highlights of recent changes will appear here.</p> <ul> <li>0.1.0 \u2014 Initial public release with:</li> <li>Dynamic compilation of services from Pydantic-typed handlers</li> <li>Unary + all streaming modes</li> <li>Dependency injection via <code>fast_depends</code></li> <li>Middlewares (logging included)</li> <li>Server reflection enabled by default</li> <li>Optional OpenTelemetry tracing middleware</li> </ul> <p>For full history, see the Git log.</p>"},{"location":"en/tutorial/first-steps/","title":"First Steps","text":"<p>Let\u2019s build a minimal gRPC service with one unary RPC.</p> <p>1) Define your request/response schemas using Pydantic models (inherit <code>BaseGRPCSchema</code>).</p> <pre><code>from fastgrpcio.schemas import BaseGRPCSchema\n\nclass Request(BaseGRPCSchema):\n    name: str\n\nclass Response(BaseGRPCSchema):\n    message: str | None\n</code></pre> <p>2) Create an app and register a function using <code>@app.register_as(\"&lt;rpc_name&gt;\")</code>.</p> <pre><code>import asyncio\nfrom fastgrpcio.fast_grpc import FastGRPC\nfrom fastgrpcio.context import GRPCContext\n\napp = FastGRPC(app_name=\"HelloApp\", app_package_name=\"hello_app\")\n\n@app.register_as(\"say_hello\")\nasync def say_hello(data: Request, context: GRPCContext) -&gt; Response:\n    return Response(message=f\"Hello, {data.name}!\")\n\nasyncio.run(app.serve())\n</code></pre> <p>3) Run the server. It listens on <code>0.0.0.0:50051</code> by default and exposes a compiled gRPC service with reflection enabled.</p> <p>You can now use <code>grpcurl</code> or any gRPC client to discover and call your service. Reflection makes the service discoverable without a <code>.proto</code> file.</p>"},{"location":"en/tutorial/handlers-and-schemas/","title":"Handlers &amp; Schemas","text":"<p>FastGRPC compiles your Python callables into gRPC RPCs by inspecting type annotations.</p> <ul> <li>Requests and responses must be Pydantic models inheriting <code>BaseGRPCSchema</code>.</li> <li>Function parameters and return types determine the RPC shape.</li> </ul> <p>Example unary handler:</p> <pre><code>from fastgrpcio.schemas import BaseGRPCSchema\nfrom fastgrpcio.context import GRPCContext\n\nclass Request(BaseGRPCSchema):\n    name: str\n\nclass Response(BaseGRPCSchema):\n    message: str | None\n\n@app.register_as(\"unary_unary\")\nasync def unary_unary(data: Request, context: GRPCContext) -&gt; Response:\n    return Response(message=f\"Hello, {data.name}\")\n</code></pre> <p>Nested models and lists are supported:</p> <pre><code>class Item(BaseGRPCSchema):\n    id: int\n    tags: list[str] | None = None\n\nclass ComplexRequest(BaseGRPCSchema):\n    items: list[Item]\n\nclass ComplexResponse(BaseGRPCSchema):\n    count: int\n</code></pre> <p>If a type is unsupported by Protobuf mapping, the compiler raises a clear error during startup.</p>"},{"location":"en/tutorial/installation/","title":"Installation","text":"<p>Install FastGRPC from PyPI. Use your preferred tool (pip, uv, poetry).</p> <p>pip:</p> <pre><code>pip install fastgrpcio\n</code></pre> <p>uv:</p> <pre><code>uv add fastgrpcio\n</code></pre> <p>Optional packages you may want:</p> <ul> <li>OpenTelemetry for tracing: <code>pip install fastgrpcio[otel]</code></li> <li>MkDocs for building these docs: <code>pip install fastgrpcio[docs]</code></li> </ul> <p>Python support: Python 3.11+ is recommended.</p>"},{"location":"en/tutorial/streaming/","title":"Streaming","text":"<p>FastGRPC supports all gRPC streaming patterns by inspecting function annotations.</p> <ul> <li>Client streaming: accept <code>AsyncIterator[RequestModel]</code>, return a single <code>ResponseModel</code>.</li> <li>Server streaming: accept a single <code>RequestModel</code>, yield <code>ResponseModel</code> instances.</li> <li>Bidirectional streaming: accept and yield <code>AsyncIterator</code>.</li> </ul> <p>Examples:</p> <p>Client streaming:</p> <pre><code>from typing import AsyncIterator\n\n@app.register_as(\"client_streaming\")\nasync def client_streaming(data: AsyncIterator[Request], context: GRPCContext) -&gt; Response:\n    values: list[str] = []\n    async for item in data:\n        values.append(item.name)\n    return Response(message=\", \".join(values))\n</code></pre> <p>Server streaming:</p> <pre><code>@app.register_as(\"server_streaming\")\nasync def server_streaming(data: Request, context: GRPCContext) -&gt; AsyncIterator[Response]:\n    for i in range(3):\n        yield Response(message=f\"Tick {i}\")\n</code></pre> <p>Bidirectional streaming:</p> <pre><code>@app.register_as(\"bidi_streaming\")\nasync def bidi_streaming(data: AsyncIterator[Request], context: GRPCContext) -&gt; AsyncIterator[Response]:\n    async for item in data:\n        yield Response(message=f\"Echo: {item.name}\")\n</code></pre>"}]}